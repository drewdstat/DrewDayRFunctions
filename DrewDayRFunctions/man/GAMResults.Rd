% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/GAMResults.R
\name{GAMResults}
\alias{GAMResults}
\title{Run multiple GAMs and return results}
\usage{
GAMResults(
  prednames,
  outnames,
  covnames = NULL,
  Data,
  logout = F,
  logpred = F,
  Outtitle = "Outcome",
  Predtitle = "Exposure",
  ixterm = NULL,
  smooth.select = F,
  bs_s = "'tp'",
  K_s = -1,
  bs_ti = "'cr'",
  K_ti = NA,
  na.action = na.exclude,
  plotresid = F,
  quantiletrimcheck = F,
  trimdim = c("x", "y"),
  trimperc = 5
)
}
\arguments{
\item{prednames}{A character vector of the predictor variables.}

\item{outnames}{A character vector of the outcome variables. The function
currently allows for numeric or binary ("factor" or "character" class) outcome
variables.}

\item{covnames}{A character vector of all covariates or a list of character
vectors of covariates of the same length as \code{length(prednames) * 
length(outnames)} so that each unique combination of prednames and outnames
has a defined set of covariates. Note that in ordering this list the function
loops through the \code{prednames} and then the \code{outnames} (e.g.,
Outcome 1 - Predictor 1, Outcome 1 - Predictor 2, Outcome 1 - Predictor 3,
Outcome 2 - Predictor 1, etc.), and so you should order the list of covariates
accordingly. These covariates will be included as linear (i.e., not smooth)
terms in the model. These can include spline terms, such as
\code{\link[splines]{ns}} natural splines or \code{\link[splines]{bs}}
b-splines as defined by the 'splines' package (e.g., \code{"ns(Year, df=3)"}).
These can also include interaction terms denoted by the ":" separator , though
you should make sure to include the main effects too (e.g., \code{c("Income", 
"HouseholdSize", "Income:HouseholdSize")}).}

\item{Data}{A data frame containing all prednames, outnames, and covnames as
columns.}

\item{logout}{A TRUE/FALSE value for whether to natural log-transform each
outcome variable. Defaults to FALSE.}

\item{logpred}{A TRUE/FALSE value for whether to natural log-transform each
predictor variable. Defaults to FALSE.}

\item{Outtitle}{A single character value for the name of the column containing
outcome variables in the data frame of results to be returned. Defaults to
"Outcome".}

\item{Predtitle}{A single character value for the name of the column containing
predictor variables in the data frame of results to be returned. Defaults to
"Exposure".}

\item{ixterm}{A single character value for the name of an interacting variable.
This variable can be either categorical, in which case the column should be
of a character or factor class, or it can be continuous.}

\item{smooth.select}{A TRUE/FALSE value for whether to add an extra penalty to
each smooth term so that it can be penalized to zero. Defaults to FALSE, and
this corresponds to the 'select' parameter in the \code{\link[mgcv]{gam}} function.}

\item{bs_s}{A character value wrapped in single quotes reflecting the basis
spline to be used in the \code{\link[mgcv]{s}} smooths, which will be used as
the smooth terms in all models except if a continuous * continous interaction
is included (i.e., if \code{ixterm} is a continuous variable, in which case
\code{\link[mgcv]{ti}} smooths are used. Defaults to \code{"'tp'"}, indicating
thin-plate regression splines (TPRS) will be used for the basis spline (see
\code{?tprs}). This is also the default basis spline for \code{\link[mgcv]{s}}.}

\item{K_s}{An integer reflecting the \code{k} parameter for \code{\link[mgcv]{s}}
smooth terms. The meaning of this term is that the maximum effective degrees
of freedom (EDF) of each smooth is this value minus one (see \code{?choose.k}).
This defaults to -1, which is the default value for \code{\link[mgcv]{s}}.
Setting K_s to -1 is the equivalent of not specifying a value, in which case
the 'k' value default value for \code{\link[mgcv]{s}} is 10 (i.e., maximum
EDF=9) when there is a single term in the smooth (e.g., \code{s(X1)}) and
\code{bs="tp"}. For your information, the default \code{k} when using
two-term smooths (e.g., \code{s(X1, X2)}) for \code{\link[mgcv]{s}} when
\code{bs="tp"} is 30 and for >=3-term smooths this is 110 (see \code{?tprs}).
Note that increasing this value increases the subspace of functions (can be
thought of as a ceiling on possible EDF values), and therefore higher
\code{K} values can lead to higher EDF (see \code{?choose.k}).}

\item{bs_ti}{A character value wrapped in single quotes reflecting the basis
spline to be used in the \code{\link[mgcv]{ti}} tensor product interaction
smooths, which will be used only if a continuous * continous interaction
is included (i.e., if \code{ixterm} is a continuous variable). Defaults to
\code{"'cr'"}, indicating cubic regression splines will be used for the basis
spline (see \code{?smooth.construct.cr.smooth.spec}).}

\item{K_ti}{An integer reflecting the \code{k} parameter for
\code{\link[mgcv]{ti}}. This defaults to NA, which is also the default \code{k}
for \code{\link[mgcv]{ti}}, and which means default \code{k} values will be used.
The documentation shown with \code{?smooth.construct.cr.smooth.spec} suggests
that the default K is 10, but in practice it appears that the default \code{k}
is actually 5 based on the \code{bsdim} values output in my own experiments.
This means 4 knots in the univariate \code{\link{ti}} terms and 4 each for the
bivariate \code{ti(var1, var2)} terms.}

\item{na.action}{This is the \code{\link[stats]{na.action}} that will be
passed to \code{\link[mgcv]{gam}}. Defaults to \code{\link[stats]{na.exclude}}.}

\item{plotresid}{A TRUE/FALSE value indicating whether the GAM plots showing
the smooth fit and CIs should also include points showing the model residuals
on the plot (see \code{\link[mgcViz]{l_points}}). Defaults to FALSE.}

\item{quantiletrimcheck}{A TRUE/FALSE value indicating whether a certain
quantile of one or both of the predictor and/or outcome variables should be
trimmed as a sensitivity analysis. Defaults to FALSE. If TRUE, the data will
be trimmed at the top \code{trimperc} percentiles. The purpose of this check
is to make sure that the observed association curves don't change radically
when removing edge points considering that splines can be at times sensitive
to data at the edges of the distribution.}

\item{trimdim}{A character value or vector of \code{"x"}, \code{"y"}, or
\code{c("x", "y")} indicating whether to trim the predictor (x) or outcome (y)
values when \code{quantiletrimcheck} is TRUE. Defaults to \code{c("x", "y")}.}

\item{trimperc}{An integer or numeric value indicating total percentage of the
data to be trimmed from the high and low ends of the data distribution if
\code{quantiletrimcheck} is TRUE. Defaults to 5, meaning that everything below
the 2.5th percentile and above the 97.5th percentile will be removed before
running the GAM models.}
}
\value{
\code{GAMResults} returns a list of:
\item{Matrix}{A data frame of important results from the GAM models.}
\item{Plots}{A list of ggplot plots of class \code{c("plotSmooth", "gg")} showing
the predictor of interest curves plotted against predicted outcome values.
These plots are based on the mgcViz package plotting functions \code{l_ciPoly},
\code{l_fitLine}, and \code{l_rug}.}
\item{GAMlist}{A list of all GAM models stored as objects of class "gam".}
\item{IxGAMlist}{If ixterm is not NULL and is a categorical variable, the
additional GAM models that were run to calculate the interaction term
coefficients are stored here as a list of "gam" class objects.}
}
\description{
\code{GAMResults} runs GAM models with smooths on a series of predictor
variables of interest for all combinations of predictor and outcome variables,
allowing for categorical and continuous interaction terms. A blog post with
some nice visualizations and explanations of what GAMs are can be
\href{https://ecogambler.netlify.app/blog/interpreting-gams/}{found here}.
}
\details{
\code{GAMResults} bases its models on the assumption that there will be only
one univariate smooth term in each model for the predictor of interest and that
utilizes the smooth function \code{\link[mgcv]{s}} with a user-defined basis spline
and "k" parameter. This is akin to \code{gam(y ~ s(x, bs = bs_s, k = K_s) + z, ...)}
where y is an outcome variable, x is a predictor variable of interest, and z
is a covariate. If an outcome variable is binary, a logistic GAM is run.

In the case of a continuous interacting variable (i.e., \code{ixterm}), this
function utilizes \code{\link[mgcv]{ti}} for univariate tensor product
interaction terms for both the predictor of interest and interaction term
(similar to main effects in a linear model with a multiplicative interaction
term), as well as a bivariate tensor product interaction for those two variables.
This is the same as \code{gam(y ~ ti(x, bs = bs_ti, k = K_ti) + ti(iota, bs = bs_ti, 
k = K_ti) + ti(x, iota, bs = bs_ti, k = K_ti) + z, ...)} where iota is the interacting
variable. This is implemented as it is in the
\href{https://pennlinc.github.io/ModelArray/reference/generator_gamFormula_continuousInteraction.html}{ModelArray R package}
and as succinctly described on this linguistics professor's
\href{https://janhove.github.io/posts/2017-06-26-continuous-interactions/}{blog post}.

In the case of a categorical interacting variable (i.e., \code{ixterm}), two
separate models are run to obtain all the relevant parameter estimates. The
first model is structured as \code{gam(y ~ s(x, bs = bs_s, k = K_s, by = iota) 
+ iota + z)}, while the second is \code{gam(y ~ s(x, bs = bs_s, k = K_s, by = 
ordered(iota)) + s(x, bs = bs_s, k = K_s) + iota + z)}. From the first model
we are able to obtain the factor level-specific curves, and from the second
model we can obtain curves of the differences between those level-specific
curves. Note that the curve for the referent level produced by
the second term "s(x)" in the second model should theoretically be equivalent
to the referent level curve produced by the first term in the first model, but
in practice they tend to have minuscule differences in EDF, exact fitted curve
values, etc., but it's close enough I find it convenient to grab terms from
these two models as if they were equivalent. Further explanation of both models can
be found at
\href{https://stats.stackexchange.com/questions/416991/gam-factor-smooth-interaction-include-main-effect-smooth}{this CrossValidated blog post}.
Examples of the second model are shown in \href{https://fromthebottomoftheheap.net/2017/12/14/difference-splines-ii/}{this blog post}
and in example papers like \href{https://www.nature.com/articles/s44161-022-00131-8}{Zhernakova et al. 2022}.
}
\examples{
# The first example involves analyzing several GAMs with no interaction terms.

set.seed(100)
gamdat1 <- data.frame(X1 = rnorm(500), X2 = rnorm(500), Z = rnorm(500,0,2))

gamdat1$yhat1 <- exp(sin(gamdat1$X1)^0.5) + gamdat1$Z * 0.75 - 2
gamdat1$yhat2 <- exp(cos(gamdat1$X2)^2) + gamdat1$Z * 2 + 3

set.seed(102)
gamdat1$y1 <- gamdat1$yhat1 + rnorm(500)
set.seed(103)
gamdat1$y2 <- gamdat1$yhat2 + rnorm(500)

gamres1 <- GAMResults(prednames = c("X1", "X2"), outnames = c("y1", "y2"), 
                      covnames = "Z", Data = gamdat1)

gridPrint(grobs = gamres1$Plots, ncol = 2)

# This next example involves a factor-smooth interaction

set.seed(100)
gamdat2 <- data.frame(X = rnorm(500), Z = rnorm(500,0,2), 
                      S = as.factor(sample(c("M","F"), 500, replace = T)))
gamdat2$yhat <- ifelse(gamdat2$S == "M", sin(gamdat2$X) * 3, 
                       sin(gamdat2$X) * 0.5)
gamdat2$yhat <- gamdat2$yhat + gamdat2$Z * 2
set.seed(101)
gamdat2$y <- gamdat2$yhat + rnorm(500)

gamres2 <- GAMResults("X", "y", "Z", gamdat2, ixterm = "S")

gridPrint(grobs = gamres2$Plots$`y~X`)

}
